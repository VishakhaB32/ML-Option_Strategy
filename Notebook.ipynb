{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\o'\n",
      "C:\\Users\\premb\\AppData\\Local\\Temp\\ipykernel_11716\\3395830572.py:4: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  df = pl.scan_parquet(\"data\\options_data_2023.parquet\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_000, 12)\n",
      "┌───────────────┬───────────────┬──────────────┬──────────────┬───┬────────┬────────┬────────┬─────┐\n",
      "│ underlying_sy ┆ ticker        ┆ datetime     ┆ expiry_date  ┆ … ┆ low    ┆ close  ┆ volume ┆ oi  │\n",
      "│ mbol          ┆ ---           ┆ ---          ┆ ---          ┆   ┆ ---    ┆ ---    ┆ ---    ┆ --- │\n",
      "│ ---           ┆ str           ┆ datetime[ms, ┆ datetime[ms] ┆   ┆ f64    ┆ f64    ┆ u32    ┆ u32 │\n",
      "│ str           ┆               ┆ Asia/Kolkata ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "│               ┆               ┆ ]            ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "╞═══════════════╪═══════════════╪══════════════╪══════════════╪═══╪════════╪════════╪════════╪═════╡\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 111.5  ┆ 111.5  ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 457.45 ┆ 457.45 ┆ 0      ┆ 0   │\n",
      "│               ┆ 9000CE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 26.0   ┆ 26.0   ┆ 0      ┆ 0   │\n",
      "│               ┆ 5000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 46.9   ┆ 46.9   ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 125.5  ┆ 130.0  ┆ 0      ┆ 0   │\n",
      "│               ┆ 7000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ …             ┆ …             ┆ …            ┆ …            ┆ … ┆ …      ┆ …      ┆ …      ┆ …   │\n",
      "│ NIFTY         ┆ NIFTY05JAN231 ┆ 2023-01-02   ┆ 2023-01-05   ┆ … ┆ 0.85   ┆ 0.95   ┆ 0      ┆ 0   │\n",
      "│               ┆ 9850CE        ┆ 09:17:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY05JAN231 ┆ 2023-01-02   ┆ 2023-01-05   ┆ … ┆ 0.85   ┆ 0.9    ┆ 0      ┆ 0   │\n",
      "│               ┆ 9900CE        ┆ 09:17:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY05JAN232 ┆ 2023-01-02   ┆ 2023-01-05   ┆ … ┆ 0.8    ┆ 0.9    ┆ 0      ┆ 0   │\n",
      "│               ┆ 0000CE        ┆ 09:17:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY05JAN232 ┆ 2023-01-02   ┆ 2023-01-05   ┆ … ┆ 0.9    ┆ 0.9    ┆ 0      ┆ 0   │\n",
      "│               ┆ 0050CE        ┆ 09:17:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY05JAN232 ┆ 2023-01-02   ┆ 2023-01-05   ┆ … ┆ 0.9    ┆ 0.9    ┆ 0      ┆ 0   │\n",
      "│               ┆ 0100CE        ┆ 09:17:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "└───────────────┴───────────────┴──────────────┴──────────────┴───┴────────┴────────┴────────┴─────┘\n",
      "['underlying_symbol', 'ticker', 'datetime', 'expiry_date', 'strike_price', 'option_type', 'open', 'high', 'low', 'close', 'volume', 'oi']\n"
     ]
    }
   ],
   "source": [
    "# options_data_2023.parquet data\n",
    "import polars as pl\n",
    "\n",
    "# Lazy loading\n",
    "df = pl.scan_parquet(\"data\\options_data_2023.parquet\")\n",
    "\n",
    "# Fetch only first 1000 rows (new method)\n",
    "sample = df.head(1000).collect()\n",
    "\n",
    "print(sample)\n",
    "print(sample.columns)   # Show column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b138ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premb\\AppData\\Local\\Temp\\ipykernel_11716\\3980237772.py:2: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  print(df.select(pl.count()).collect())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────────┐\n",
      "│ count    │\n",
      "│ ---      │\n",
      "│ u32      │\n",
      "╞══════════╡\n",
      "│ 42146262 │\n",
      "└──────────┘\n",
      "shape: (1, 1)\n",
      "┌───────────────────┐\n",
      "│ underlying_symbol │\n",
      "│ ---               │\n",
      "│ str               │\n",
      "╞═══════════════════╡\n",
      "│ NIFTY             │\n",
      "└───────────────────┘\n",
      "shape: (1, 2)\n",
      "┌────────────────────────────┬────────────────────────────┐\n",
      "│ start                      ┆ end                        │\n",
      "│ ---                        ┆ ---                        │\n",
      "│ datetime[ms, Asia/Kolkata] ┆ datetime[ms, Asia/Kolkata] │\n",
      "╞════════════════════════════╪════════════════════════════╡\n",
      "│ 2023-01-02 09:15:00 IST    ┆ 2023-12-29 15:29:00 IST    │\n",
      "└────────────────────────────┴────────────────────────────┘\n",
      "shape: (70, 1)\n",
      "┌─────────────────────┐\n",
      "│ expiry_date         │\n",
      "│ ---                 │\n",
      "│ datetime[ms]        │\n",
      "╞═════════════════════╡\n",
      "│ 2023-01-05 00:00:00 │\n",
      "│ 2023-01-12 00:00:00 │\n",
      "│ 2023-01-19 00:00:00 │\n",
      "│ 2023-01-25 00:00:00 │\n",
      "│ 2023-02-02 00:00:00 │\n",
      "│ …                   │\n",
      "│ 2026-06-25 00:00:00 │\n",
      "│ 2026-12-31 00:00:00 │\n",
      "│ 2027-06-24 00:00:00 │\n",
      "│ 2027-12-30 00:00:00 │\n",
      "│ 2028-06-29 00:00:00 │\n",
      "└─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# How many rows in total?\n",
    "print(df.select(pl.count()).collect())\n",
    "\n",
    "# What symbols are there?\n",
    "print(df.select(pl.col(\"underlying_symbol\").unique()).collect())\n",
    "\n",
    "# Date range\n",
    "print(df.select([\n",
    "    pl.col(\"datetime\").min().alias(\"start\"),\n",
    "    pl.col(\"datetime\").max().alias(\"end\")\n",
    "]).collect())\n",
    "\n",
    "# Check unique expiry dates\n",
    "print(df.select(pl.col(\"expiry_date\").unique()).collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40eb8da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/28/30/8114832daff7489f179971dbc1d854109b7f4365a546e3ea75b6516cea95/pandas-2.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pandas-2.3.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.26.0 from https://files.pythonhosted.org/packages/32/ee/de999f2625b80d043d6d2d628c07d0d5555a677a3cf78fdf868d409b8766/numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 60.9/60.9 kB 817.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\vishakha program files\\vishakha_quant_research\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\vishakha program files\\vishakha_quant_research\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/11.0 MB 12.2 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.7/11.0 MB 9.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.0 MB 8.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 7.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 7.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/11.0 MB 7.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.0 MB 7.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.0 MB 6.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.7/11.0 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.0 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.0/11.0 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.3/11.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.3/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.6/11.0 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.9/11.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.6/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.8/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.0/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.1/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.4/11.0 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.5/11.0 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.7/11.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.3/11.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.3/11.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.5/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.0/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.6/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.3-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.8 MB 660.6 kB/s eta 0:00:20\n",
      "   ---------------------------------------- 0.1/12.8 MB 1.1 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.2/12.8 MB 1.4 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.3/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.5/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.5/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.5/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.6/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.7/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.8/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/12.8 MB 1.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.2/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.4/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.4/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.5/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.9/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.3/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.5/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.7/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.9/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.1/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.2/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.5/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.6/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.8/12.8 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.0/12.8 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.4/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.6/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.9/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.1/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.4/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.6/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.9/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.2/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.4/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.0/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.2/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.4/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.7/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.8/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.0/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.2/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.3/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.4/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.6/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.8/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.0/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.1/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.8 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.8 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.9/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.2/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 4.5 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.3 pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99c4858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\premb\\AppData\\Local\\Temp\\ipykernel_11736\\3204000894.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(\"data\\spot_with_signals_2023.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    datetime      open      high       low     close  \\\n",
      "0  2023-01-02 09:20:00+05:30  18131.70  18150.15  18117.55  18141.35   \n",
      "1  2023-01-02 09:21:00+05:30  18142.20  18145.70  18131.40  18135.65   \n",
      "2  2023-01-02 09:22:00+05:30  18133.25  18140.55  18120.65  18140.55   \n",
      "3  2023-01-02 09:23:00+05:30  18139.40  18139.40  18120.15  18130.75   \n",
      "4  2023-01-02 09:24:00+05:30  18130.30  18133.55  18113.05  18113.10   \n",
      "\n",
      "  closest_expiry        ap       esa      d     ci    tci    wt1    wt2  \\\n",
      "0     2023-01-05  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78   \n",
      "1     2023-01-05  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78   \n",
      "2     2023-01-05  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78   \n",
      "3     2023-01-05  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78   \n",
      "4     2023-01-05  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78   \n",
      "\n",
      "     rsi  cross signal  \n",
      "0  39.45    NaN   Hold  \n",
      "1  39.45    NaN   Hold  \n",
      "2  39.45    NaN   Hold  \n",
      "3  39.45    NaN   Hold  \n",
      "4  39.45    NaN   Hold  \n",
      "Index(['datetime', 'open', 'high', 'low', 'close', 'closest_expiry', 'ap',\n",
      "       'esa', 'd', 'ci', 'tci', 'wt1', 'wt2', 'rsi', 'cross', 'signal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data\\spot_with_signals_2023.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118cab7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "pa.Table requires 'pyarrow' module to be installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m spot = load_spot_data()\n\u001b[32m      4\u001b[39m options = load_options_data()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_test = \u001b[43mprepare_trades_for_day\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2023-01-02\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_test.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research\\data_prep.py:18\u001b[39m, in \u001b[36mprepare_trades_for_day\u001b[39m\u001b[34m(spot, options, date_str)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Extracts spot + matching options data for a given trading day\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m spot_day = spot[spot[\u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m].dt.date == pd.to_datetime(date_str).date()]\n\u001b[32m     16\u001b[39m options_day = \u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatetime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m merged_trades = []\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m spot_day.iterrows():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research\\venv\\Lib\\site-packages\\polars\\dataframe\\frame.py:2561\u001b[39m, in \u001b[36mDataFrame.to_pandas\u001b[39m\u001b[34m(self, use_pyarrow_extension_array, **kwargs)\u001b[39m\n\u001b[32m   2556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Object \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtypes:\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._to_pandas_with_object_columns(\n\u001b[32m   2558\u001b[39m         use_pyarrow_extension_array=use_pyarrow_extension_array, **kwargs\n\u001b[32m   2559\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_pandas_without_object_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   2563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research\\venv\\Lib\\site-packages\\polars\\dataframe\\frame.py:2613\u001b[39m, in \u001b[36mDataFrame._to_pandas_without_object_columns\u001b[39m\u001b[34m(self, df, use_pyarrow_extension_array, **kwargs)\u001b[39m\n\u001b[32m   2610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame()\n\u001b[32m   2612\u001b[39m record_batches = df._df.to_pandas()\n\u001b[32m-> \u001b[39m\u001b[32m2613\u001b[39m tbl = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m.from_batches(record_batches)\n\u001b[32m   2614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pyarrow_extension_array:\n\u001b[32m   2615\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tbl.to_pandas(\n\u001b[32m   2616\u001b[39m         self_destruct=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2617\u001b[39m         split_blocks=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2618\u001b[39m         types_mapper=\u001b[38;5;28;01mlambda\u001b[39;00m pa_dtype: pd.ArrowDtype(pa_dtype),\n\u001b[32m   2619\u001b[39m         **kwargs,\n\u001b[32m   2620\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research\\venv\\Lib\\site-packages\\polars\\dependencies.py:102\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    100\u001b[39m pfx = \u001b[38;5;28mself\u001b[39m._mod_pfx.get(\u001b[38;5;28mself\u001b[39m._module_name, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpfx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._module_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m module to be installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: pa.Table requires 'pyarrow' module to be installed"
     ]
    }
   ],
   "source": [
    "from data_prep import load_spot_data, load_options_data, prepare_trades_for_day\n",
    "import pyarrow as pa\n",
    "spot = load_spot_data()\n",
    "options = load_options_data()\n",
    "\n",
    "df_test = prepare_trades_for_day(spot, options, \"2023-01-02\")\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c62121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 12)\n",
      "┌───────────────────┬────────┬───────────────┬──────────────┬───┬─────┬───────┬────────┬─────┐\n",
      "│ underlying_symbol ┆ ticker ┆ datetime      ┆ expiry_date  ┆ … ┆ low ┆ close ┆ volume ┆ oi  │\n",
      "│ ---               ┆ ---    ┆ ---           ┆ ---          ┆   ┆ --- ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str               ┆ str    ┆ datetime[ms,  ┆ datetime[ms] ┆   ┆ f64 ┆ f64   ┆ u32    ┆ u32 │\n",
      "│                   ┆        ┆ Asia/Kolkata] ┆              ┆   ┆     ┆       ┆        ┆     │\n",
      "╞═══════════════════╪════════╪═══════════════╪══════════════╪═══╪═════╪═══════╪════════╪═════╡\n",
      "└───────────────────┴────────┴───────────────┴──────────────┴───┴─────┴───────┴────────┴─────┘\n",
      "['underlying_symbol', 'ticker', 'datetime', 'expiry_date', 'strike_price', 'option_type', 'open', 'high', 'low', 'close', 'volume', 'oi']\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "options = pl.scan_parquet(\"data/options_data_2023.parquet\", use_statistics=True)\n",
    "\n",
    "sample = options.filter(\n",
    "    pl.col(\"datetime\").dt.date() == pd.to_datetime(\"2023-01-02\").date()\n",
    ").collect()\n",
    "\n",
    "print(sample.head())\n",
    "print(sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d030e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 12)\n",
      "┌───────────────────┬────────┬───────────────┬──────────────┬───┬─────┬───────┬────────┬─────┐\n",
      "│ underlying_symbol ┆ ticker ┆ datetime      ┆ expiry_date  ┆ … ┆ low ┆ close ┆ volume ┆ oi  │\n",
      "│ ---               ┆ ---    ┆ ---           ┆ ---          ┆   ┆ --- ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str               ┆ str    ┆ datetime[ms,  ┆ datetime[ms] ┆   ┆ f64 ┆ f64   ┆ u32    ┆ u32 │\n",
      "│                   ┆        ┆ Asia/Kolkata] ┆              ┆   ┆     ┆       ┆        ┆     │\n",
      "╞═══════════════════╪════════╪═══════════════╪══════════════╪═══╪═════╪═══════╪════════╪═════╡\n",
      "└───────────────────┴────────┴───────────────┴──────────────┴───┴─────┴───────┴────────┴─────┘\n",
      "(0, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pytz\n",
    "\n",
    "options = pl.scan_parquet(\"data/options_data_2023.parquet\", use_statistics=True)\n",
    "\n",
    "# Define timezone-aware start and end\n",
    "tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "start = pd.to_datetime(\"2023-01-02 09:15:00\").tz_localize(tz)\n",
    "end   = pd.to_datetime(\"2023-01-02 15:30:00\").tz_localize(tz)\n",
    "\n",
    "# Filter with timezone-aware bounds\n",
    "sample = options.filter(\n",
    "    (pl.col(\"datetime\") >= start) &\n",
    "    (pl.col(\"datetime\") <= end)\n",
    ").collect()\n",
    "\n",
    "print(sample.head())\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de32d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 12)\n",
      "┌───────────────┬───────────────┬──────────────┬──────────────┬───┬────────┬────────┬────────┬─────┐\n",
      "│ underlying_sy ┆ ticker        ┆ datetime     ┆ expiry_date  ┆ … ┆ low    ┆ close  ┆ volume ┆ oi  │\n",
      "│ mbol          ┆ ---           ┆ ---          ┆ ---          ┆   ┆ ---    ┆ ---    ┆ ---    ┆ --- │\n",
      "│ ---           ┆ str           ┆ datetime[ms, ┆ datetime[ms] ┆   ┆ f64    ┆ f64    ┆ u32    ┆ u32 │\n",
      "│ str           ┆               ┆ Asia/Kolkata ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "│               ┆               ┆ ]            ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "╞═══════════════╪═══════════════╪══════════════╪══════════════╪═══╪════════╪════════╪════════╪═════╡\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 111.5  ┆ 111.5  ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 457.45 ┆ 457.45 ┆ 0      ┆ 0   │\n",
      "│               ┆ 9000CE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 26.0   ┆ 26.0   ┆ 0      ┆ 0   │\n",
      "│               ┆ 5000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 46.9   ┆ 46.9   ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 125.5  ┆ 130.0  ┆ 0      ┆ 0   │\n",
      "│               ┆ 7000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "└───────────────┴───────────────┴──────────────┴──────────────┴───┴────────┴────────┴────────┴─────┘\n",
      "shape: (5,)\n",
      "Series: 'datetime' [datetime[ms, Asia/Kolkata]]\n",
      "[\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sample = options.collect().head(5)\n",
    "print(sample)\n",
    "print(sample[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112a8f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 12)\n",
      "┌───────────────┬───────────────┬──────────────┬──────────────┬───┬────────┬────────┬────────┬─────┐\n",
      "│ underlying_sy ┆ ticker        ┆ datetime     ┆ expiry_date  ┆ … ┆ low    ┆ close  ┆ volume ┆ oi  │\n",
      "│ mbol          ┆ ---           ┆ ---          ┆ ---          ┆   ┆ ---    ┆ ---    ┆ ---    ┆ --- │\n",
      "│ ---           ┆ str           ┆ datetime[ms, ┆ datetime[ms] ┆   ┆ f64    ┆ f64    ┆ u32    ┆ u32 │\n",
      "│ str           ┆               ┆ Asia/Kolkata ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "│               ┆               ┆ ]            ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "╞═══════════════╪═══════════════╪══════════════╪══════════════╪═══╪════════╪════════╪════════╪═════╡\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 111.5  ┆ 111.5  ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 457.45 ┆ 457.45 ┆ 0      ┆ 0   │\n",
      "│               ┆ 9000CE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 26.0   ┆ 26.0   ┆ 0      ┆ 0   │\n",
      "│               ┆ 5000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 46.9   ┆ 46.9   ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 125.5  ┆ 130.0  ┆ 0      ┆ 0   │\n",
      "│               ┆ 7000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "└───────────────┴───────────────┴──────────────┴──────────────┴───┴────────┴────────┴────────┴─────┘\n",
      "(99022, 12)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "options = pl.read_parquet(\"data/options_data_2023.parquet\")\n",
    "\n",
    "day_sample = options.filter(\n",
    "    options[\"datetime\"].dt.date() == pl.date(2023, 1, 2)\n",
    ")\n",
    "\n",
    "print(day_sample.head())\n",
    "print(day_sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20510298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options rows on 2023-01-02: (99022, 12)\n",
      "shape: (5, 12)\n",
      "┌───────────────┬───────────────┬──────────────┬──────────────┬───┬────────┬────────┬────────┬─────┐\n",
      "│ underlying_sy ┆ ticker        ┆ datetime     ┆ expiry_date  ┆ … ┆ low    ┆ close  ┆ volume ┆ oi  │\n",
      "│ mbol          ┆ ---           ┆ ---          ┆ ---          ┆   ┆ ---    ┆ ---    ┆ ---    ┆ --- │\n",
      "│ ---           ┆ str           ┆ datetime[ms, ┆ datetime[ms] ┆   ┆ f64    ┆ f64    ┆ u32    ┆ u32 │\n",
      "│ str           ┆               ┆ Asia/Kolkata ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "│               ┆               ┆ ]            ┆              ┆   ┆        ┆        ┆        ┆     │\n",
      "╞═══════════════╪═══════════════╪══════════════╪══════════════╪═══╪════════╪════════╪════════╪═════╡\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 111.5  ┆ 111.5  ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29JUN231 ┆ 2023-01-02   ┆ 2023-06-29   ┆ … ┆ 457.45 ┆ 457.45 ┆ 0      ┆ 0   │\n",
      "│               ┆ 9000CE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 26.0   ┆ 26.0   ┆ 0      ┆ 0   │\n",
      "│               ┆ 5000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 46.9   ┆ 46.9   ┆ 0      ┆ 0   │\n",
      "│               ┆ 6000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "│ NIFTY         ┆ NIFTY29MAR231 ┆ 2023-01-02   ┆ 2023-03-29   ┆ … ┆ 125.5  ┆ 130.0  ┆ 0      ┆ 0   │\n",
      "│               ┆ 7000PE        ┆ 09:15:00 IST ┆ 00:00:00     ┆   ┆        ┆        ┆        ┆     │\n",
      "└───────────────┴───────────────┴──────────────┴──────────────┴───┴────────┴────────┴────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "#back testing data_prep\n",
    "from data_prep import load_spot_data, load_options_data, prepare_trades_for_day\n",
    "spot = load_spot_data()\n",
    "options = load_options_data()\n",
    "\n",
    "df_test = prepare_trades_for_day(spot, options, \"2023-01-02\")\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92fc6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[String, String, Datetime(time_unit='ms', time_zone='Asia/Kolkata'), Datetime(time_unit='ms', time_zone=None), Float32, String, Float64, Float64, Float64, Float64, UInt32, UInt32]\n",
      "Schema({'underlying_symbol': String, 'ticker': String, 'datetime': Datetime(time_unit='ms', time_zone='Asia/Kolkata'), 'expiry_date': Datetime(time_unit='ms', time_zone=None), 'strike_price': Float32, 'option_type': String, 'open': Float64, 'high': Float64, 'low': Float64, 'close': Float64, 'volume': UInt32, 'oi': UInt32})\n"
     ]
    }
   ],
   "source": [
    "print(options.dtypes)\n",
    "print(options.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc1cb12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-01-02 09:20:00+05:30\n",
      "1   2023-01-02 09:21:00+05:30\n",
      "2   2023-01-02 09:22:00+05:30\n",
      "Name: datetime, dtype: datetime64[ns, UTC+05:30]\n",
      "tz info: UTC+05:30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spot = pd.read_csv(\"data/spot_with_signals_2023.csv\", parse_dates=[\"datetime\"])\n",
    "print(spot[\"datetime\"].head(3))\n",
    "print(\"tz info:\", spot[\"datetime\"].dt.tz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb95800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot head:\n",
      " 0   2023-01-02 09:20:00+05:30\n",
      "1   2023-01-02 09:21:00+05:30\n",
      "2   2023-01-02 09:22:00+05:30\n",
      "3   2023-01-02 09:23:00+05:30\n",
      "4   2023-01-02 09:24:00+05:30\n",
      "Name: datetime, dtype: datetime64[ns, UTC+05:30]\n",
      "Spot tz info: UTC+05:30\n",
      "Options head:\n",
      " shape: (5,)\n",
      "Series: 'datetime' [datetime[ms, Asia/Kolkata]]\n",
      "[\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "\t2023-01-02 09:15:00 IST\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "# Spot check\n",
    "spot = pd.read_csv(\"data/spot_with_signals_2023.csv\", parse_dates=[\"datetime\"])\n",
    "print(\"Spot head:\\n\", spot[\"datetime\"].head())\n",
    "print(\"Spot tz info:\", spot[\"datetime\"].dt.tz)\n",
    "\n",
    "# Options check (first 5 rows after collect)\n",
    "import polars as pl\n",
    "options = pl.scan_parquet(\"data/options_data_2023.parquet\")\n",
    "sample = options.head().collect()\n",
    "print(\"Options head:\\n\", sample[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070e72a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'underlying_symbol': String, 'ticker': String, 'datetime': Datetime(time_unit='ms', time_zone=None), 'expiry_date': Datetime(time_unit='ms', time_zone=None), 'strike_price': Float32, 'option_type': String, 'open': Float64, 'high': Float64, 'low': Float64, 'close': Float64, 'volume': UInt32, 'oi': UInt32})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premb\\AppData\\Local\\Temp\\ipykernel_25872\\1401909773.py:2: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  print(options.schema)\n"
     ]
    }
   ],
   "source": [
    "options = load_options_data()\n",
    "print(options.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e55d0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prep.py\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def load_spot_data(path=\"data/spot_with_signals_2023.csv\"):\n",
    "    df = pd.read_csv(path, parse_dates=[\"datetime\"])\n",
    "    df[\"datetime\"] = df[\"datetime\"].dt.tz_convert(None)   # tz-naive\n",
    "    df[\"closest_expiry\"] = pd.to_datetime(df[\"closest_expiry\"], errors=\"coerce\")  # ✅ force datetime\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def load_options_data(path=\"data/options_data_2023.parquet\"):\n",
    "    \"\"\"\n",
    "    Load options data using Polars (lazy).\n",
    "    Ensures datetime columns are timezone-naive.\n",
    "    \"\"\"\n",
    "    lf = pl.scan_parquet(path, use_statistics=True)\n",
    "    \n",
    "    # make datetime tz-naive\n",
    "    lf = lf.with_columns([\n",
    "        pl.col(\"datetime\").dt.replace_time_zone(None),\n",
    "        pl.col(\"expiry_date\").dt.replace_time_zone(None)\n",
    "    ])\n",
    "    \n",
    "    return lf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b4cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_trades_for_day.py\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def find_atm_strike(spot_price, strikes):\n",
    "    \"\"\"Find nearest strike to spot price.\"\"\"\n",
    "    return min(strikes, key=lambda x: abs(x - spot_price))\n",
    "\n",
    "\n",
    "def prepare_trades_for_day(spot, options, date_str):\n",
    "    \"\"\"Extracts spot + matching options data for a given trading day (Polars only).\"\"\"\n",
    "\n",
    "    # --- Filter spot for this date ---\n",
    "    spot_day = spot[spot[\"datetime\"].dt.date == pd.to_datetime(date_str).date()]\n",
    "\n",
    "    # --- Define trading session start/end ---\n",
    "    start = pd.to_datetime(f\"{date_str} 09:15:00\").to_pydatetime().replace(tzinfo=None)\n",
    "    end   = pd.to_datetime(f\"{date_str} 15:30:00\").to_pydatetime().replace(tzinfo=None)\n",
    "\n",
    "    # --- Filter options for this day (Polars) ---\n",
    "    options_day = options.filter(\n",
    "        (pl.col(\"datetime\") >= start) &\n",
    "        (pl.col(\"datetime\") <= end)\n",
    "    ).collect()\n",
    "\n",
    "    merged_trades = []\n",
    "\n",
    "    # --- Loop through each spot row (signal) ---\n",
    "    for _, row in spot_day.iterrows():\n",
    "        if row[\"signal\"] in [\"Buy\", \"Sell\"]:\n",
    "            expiry = pd.to_datetime(row[\"closest_expiry\"]).to_pydatetime().replace(tzinfo=None)\n",
    "            row_dt = pd.to_datetime(row[\"datetime\"]).to_pydatetime().replace(tzinfo=None)\n",
    "            spot_price = row[\"close\"]\n",
    "\n",
    "            # --- Debug print types ---\n",
    "            print(f\"[DEBUG] expiry={expiry} ({type(expiry)}), row_dt={row_dt} ({type(row_dt)})\")\n",
    "\n",
    "            # ✅ Use pl.lit with explicit dtype=Datetime\n",
    "            subset = options_day.filter(\n",
    "                (pl.col(\"expiry_date\") == pl.lit(expiry, dtype=pl.Datetime)) &\n",
    "                (pl.col(\"datetime\") == pl.lit(row_dt, dtype=pl.Datetime))\n",
    "            )\n",
    "\n",
    "            if subset.height == 0:\n",
    "                continue\n",
    "\n",
    "            # get ATM strike\n",
    "            strikes = subset.select(\"strike_price\").unique().to_series().to_list()\n",
    "            atm_strike = find_atm_strike(spot_price, strikes)\n",
    "\n",
    "            # select trade leg\n",
    "            if row[\"signal\"] == \"Buy\":\n",
    "                trade = subset.filter(\n",
    "                    (pl.col(\"strike_price\") == atm_strike) & \n",
    "                    (pl.col(\"option_type\") == \"PE\")\n",
    "                )\n",
    "            else:\n",
    "                trade = subset.filter(\n",
    "                    (pl.col(\"strike_price\") == atm_strike) & \n",
    "                    (pl.col(\"option_type\") == \"CE\")\n",
    "                )\n",
    "\n",
    "            if trade.height > 0:\n",
    "                trade_price = trade.select(\"close\").to_series().to_list()[0]\n",
    "                merged_trades.append({\n",
    "                    \"datetime\": row_dt,\n",
    "                    \"signal\": row[\"signal\"],\n",
    "                    \"spot_close\": spot_price,\n",
    "                    \"expiry\": expiry,\n",
    "                    \"strike\": atm_strike,\n",
    "                    \"option_type\": \"PE\" if row[\"signal\"] == \"Buy\" else \"CE\",\n",
    "                    \"entry_price\": trade_price\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(merged_trades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5eedae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'composite_signal'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research - Copy\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'composite_signal'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m spot = load_spot_data()\n\u001b[32m      6\u001b[39m options = load_options_data()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df_trades = \u001b[43mprepare_trades_for_day\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2023-01-02\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_trades.head())\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_trades.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research - Copy\\prepare_trades_for_day.py:254\u001b[39m, in \u001b[36mprepare_trades_for_day\u001b[39m\u001b[34m(spot, options, date_str, capital, sl, tp, force_exit, strategy_label)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# --- Loop through each spot row (composite signal) ---\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m spot_day.iterrows():\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcomposite_signal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mBuy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSell\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    255\u001b[39m         expiry = pd.to_datetime(row[\u001b[33m\"\u001b[39m\u001b[33mclosest_expiry\u001b[39m\u001b[33m\"\u001b[39m]).to_pydatetime().replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    256\u001b[39m         row_dt = pd.to_datetime(row[\u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m]).to_pydatetime().replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research - Copy\\venv\\Lib\\site-packages\\pandas\\core\\series.py:1130\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research - Copy\\venv\\Lib\\site-packages\\pandas\\core\\series.py:1246\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Vishakha program files\\Vishakha_Quant_research - Copy\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'composite_signal'"
     ]
    }
   ],
   "source": [
    "#backtesting prepare_trades_for_day\n",
    "from data_prep import load_spot_data, load_options_data\n",
    "from prepare_trades_for_day import prepare_trades_for_day\n",
    "\n",
    "spot = load_spot_data()\n",
    "options = load_options_data()\n",
    "\n",
    "df_trades = prepare_trades_for_day(spot, options, \"2023-01-02\")\n",
    "print(df_trades.head())\n",
    "print(df_trades.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f65bf7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot sample: [Timestamp('2023-01-02 03:50:00'), Timestamp('2023-01-02 03:51:00'), Timestamp('2023-01-02 03:52:00'), Timestamp('2023-01-02 03:53:00'), Timestamp('2023-01-02 03:54:00'), Timestamp('2023-01-02 03:55:00'), Timestamp('2023-01-02 03:56:00'), Timestamp('2023-01-02 03:57:00'), Timestamp('2023-01-02 03:58:00'), Timestamp('2023-01-02 03:59:00')]\n"
     ]
    }
   ],
   "source": [
    "spot_day = spot[spot[\"datetime\"].dt.date == pd.to_datetime(\"2023-01-02\").date()]\n",
    "print(\"Spot sample:\", spot_day[\"datetime\"].head(10).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "002b6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options sample: shape: (10, 1)\n",
      "┌─────────────────────┐\n",
      "│ datetime            │\n",
      "│ ---                 │\n",
      "│ datetime[ms]        │\n",
      "╞═════════════════════╡\n",
      "│ 2023-01-02 09:15:00 │\n",
      "│ 2023-01-02 09:16:00 │\n",
      "│ 2023-01-02 09:17:00 │\n",
      "│ 2023-01-02 09:18:00 │\n",
      "│ 2023-01-02 09:19:00 │\n",
      "│ 2023-01-02 09:20:00 │\n",
      "│ 2023-01-02 09:21:00 │\n",
      "│ 2023-01-02 09:22:00 │\n",
      "│ 2023-01-02 09:23:00 │\n",
      "│ 2023-01-02 09:24:00 │\n",
      "└─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "options_day = options.filter(\n",
    "    (pl.col(\"datetime\") >= pd.to_datetime(\"2023-01-02 09:15:00\")) &\n",
    "    (pl.col(\"datetime\") <= pd.to_datetime(\"2023-01-02 15:30:00\"))\n",
    ").select(\"datetime\").unique().sort(\"datetime\").collect()\n",
    "\n",
    "print(\"Options sample:\", options_day.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a3857d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot fixed sample: [Timestamp('2023-01-02 09:20:00'), Timestamp('2023-01-02 09:21:00'), Timestamp('2023-01-02 09:22:00'), Timestamp('2023-01-02 09:23:00'), Timestamp('2023-01-02 09:24:00'), Timestamp('2023-01-02 09:25:00'), Timestamp('2023-01-02 09:26:00'), Timestamp('2023-01-02 09:27:00'), Timestamp('2023-01-02 09:28:00'), Timestamp('2023-01-02 09:29:00')]\n",
      "             datetime signal  spot_close     expiry   strike option_type  \\\n",
      "0 2023-01-02 11:25:00   Sell    18190.05 2023-01-05  18200.0          CE   \n",
      "1 2023-01-02 12:15:00    Buy    18185.35 2023-01-05  18200.0          PE   \n",
      "2 2023-01-02 12:30:00   Sell    18168.70 2023-01-05  18150.0          CE   \n",
      "3 2023-01-02 13:10:00    Buy    18173.85 2023-01-05  18150.0          PE   \n",
      "4 2023-01-02 13:45:00   Sell    18180.00 2023-01-05  18200.0          CE   \n",
      "\n",
      "   entry_price  \n",
      "0        94.30  \n",
      "1        96.35  \n",
      "2       115.20  \n",
      "3        78.35  \n",
      "4        89.55  \n",
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# ---------------------------\n",
    "# Data Loading Functions\n",
    "# ---------------------------\n",
    "\n",
    "# def load_spot_data(path=\"data/spot_with_signals_2023.csv\"):\n",
    "#     df = pd.read_csv(path, parse_dates=[\"datetime\", \"closest_expiry\"])\n",
    "\n",
    "#     # ✅ Force UTC first (because your spot file shows UTC times like 03:50 instead of 09:20)\n",
    "#     df[\"datetime\"] = df[\"datetime\"].dt.tz_localize(\"UTC\").dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "#     # ✅ finally strip tz → make tz-naive (to align with options)\n",
    "#     df[\"datetime\"] = df[\"datetime\"].dt.tz_convert(None)\n",
    "\n",
    "#     # expiry as datetime\n",
    "#     df[\"closest_expiry\"] = pd.to_datetime(df[\"closest_expiry\"])\n",
    "\n",
    "#     return df\n",
    "def load_spot_data(path=\"data/spot_with_signals_2023.csv\"):\n",
    "    df = pd.read_csv(path, parse_dates=[\"datetime\", \"closest_expiry\"])\n",
    "\n",
    "    # ✅ Force all datetimes to tz-naive first\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], utc=False).dt.tz_localize(None)\n",
    "\n",
    "    # ✅ Now safely localize as UTC and convert to IST\n",
    "    df[\"datetime\"] = df[\"datetime\"].dt.tz_localize(\"UTC\").dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "    # ✅ Strip tz → tz-naive (to match options parquet)\n",
    "    df[\"datetime\"] = df[\"datetime\"].dt.tz_convert(None)\n",
    "\n",
    "    # expiry as datetime\n",
    "    df[\"closest_expiry\"] = pd.to_datetime(df[\"closest_expiry\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_options_data(path=\"data/options_data_2023.parquet\"):\n",
    "    \"\"\"\n",
    "    Load options data using Polars (lazy).\n",
    "    Ensures datetime columns are tz-naive.\n",
    "    \"\"\"\n",
    "    lf = pl.scan_parquet(path, use_statistics=True)\n",
    "    lf = lf.with_columns([\n",
    "        pl.col(\"datetime\").dt.replace_time_zone(None),\n",
    "        pl.col(\"expiry_date\").dt.replace_time_zone(None)\n",
    "    ])\n",
    "    return lf\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Trade Preparation Function\n",
    "# ---------------------------\n",
    "\n",
    "def find_atm_strike(spot_price, strikes):\n",
    "    \"\"\"Find nearest strike to spot price.\"\"\"\n",
    "    return min(strikes, key=lambda x: abs(x - spot_price))\n",
    "\n",
    "\n",
    "def prepare_trades_for_day(spot, options, date_str):\n",
    "    \"\"\"Extracts spot + matching options data for a given trading day (with 1-min tolerance).\"\"\"\n",
    "\n",
    "    # --- Filter spot for this date ---\n",
    "    spot_day = spot[spot[\"datetime\"].dt.date == pd.to_datetime(date_str).date()]\n",
    "\n",
    "    # --- Define trading session start/end ---\n",
    "    start = pd.to_datetime(f\"{date_str} 09:15:00\").to_pydatetime()\n",
    "    end   = pd.to_datetime(f\"{date_str} 15:30:00\").to_pydatetime()\n",
    "\n",
    "    # --- Filter options for this day ---\n",
    "    options_day = options.filter(\n",
    "        (pl.col(\"datetime\") >= start) &\n",
    "        (pl.col(\"datetime\") <= end)\n",
    "    ).collect()\n",
    "\n",
    "    merged_trades = []\n",
    "\n",
    "    # --- Loop through each spot row (signal) ---\n",
    "    for _, row in spot_day.iterrows():\n",
    "        if row[\"signal\"] in [\"Buy\", \"Sell\"]:\n",
    "            expiry = pd.to_datetime(row[\"closest_expiry\"]).to_pydatetime().replace(tzinfo=None)\n",
    "            row_dt = pd.to_datetime(row[\"datetime\"]).to_pydatetime().replace(tzinfo=None)\n",
    "            spot_price = row[\"close\"]\n",
    "\n",
    "            # ✅ allow 1-minute tolerance window instead of strict equality\n",
    "            subset = options_day.filter(\n",
    "                (pl.col(\"expiry_date\") == pl.lit(expiry, dtype=pl.Datetime)) &\n",
    "                (pl.col(\"datetime\") >= pl.lit(row_dt, dtype=pl.Datetime)) &\n",
    "                (pl.col(\"datetime\") < pl.lit(row_dt + pd.Timedelta(minutes=1), dtype=pl.Datetime))\n",
    "            )\n",
    "\n",
    "            if subset.height == 0:\n",
    "                continue\n",
    "\n",
    "            # get ATM strike\n",
    "            strikes = subset.select(\"strike_price\").unique().to_series().to_list()\n",
    "            atm_strike = find_atm_strike(spot_price, strikes)\n",
    "\n",
    "            # select trade leg\n",
    "            if row[\"signal\"] == \"Buy\":\n",
    "                trade = subset.filter(\n",
    "                    (pl.col(\"strike_price\") == atm_strike) & \n",
    "                    (pl.col(\"option_type\") == \"PE\")\n",
    "                )\n",
    "            else:\n",
    "                trade = subset.filter(\n",
    "                    (pl.col(\"strike_price\") == atm_strike) & \n",
    "                    (pl.col(\"option_type\") == \"CE\")\n",
    "                )\n",
    "\n",
    "            if trade.height > 0:\n",
    "                trade_price = trade.select(\"close\").to_series().to_list()[0]\n",
    "                merged_trades.append({\n",
    "                    \"datetime\": row_dt,\n",
    "                    \"signal\": row[\"signal\"],\n",
    "                    \"spot_close\": spot_price,\n",
    "                    \"expiry\": expiry,\n",
    "                    \"strike\": atm_strike,\n",
    "                    \"option_type\": \"PE\" if row[\"signal\"] == \"Buy\" else \"CE\",\n",
    "                    \"entry_price\": trade_price\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(merged_trades)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Test Run for One Day\n",
    "# ---------------------------\n",
    "\n",
    "spot = load_spot_data()\n",
    "options = load_options_data()\n",
    "\n",
    "print(\"Spot fixed sample:\", spot[\"datetime\"].head(10).tolist())\n",
    "\n",
    "df_trades = prepare_trades_for_day(spot, options, \"2023-01-02\")\n",
    "print(df_trades.head())\n",
    "print(df_trades.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9b7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    datetime     close signal composite_signal\n",
      "0  2023-01-02 09:20:00+05:30  18141.35   Hold             Hold\n",
      "1  2023-01-02 09:21:00+05:30  18135.65   Hold             Sell\n",
      "2  2023-01-02 09:22:00+05:30  18140.55   Hold             Sell\n",
      "3  2023-01-02 09:23:00+05:30  18130.75   Hold             Sell\n",
      "4  2023-01-02 09:24:00+05:30  18113.10   Hold             Sell\n",
      "5  2023-01-02 09:25:00+05:30  18117.85   Hold             Sell\n",
      "6  2023-01-02 09:26:00+05:30  18122.75   Hold             Sell\n",
      "7  2023-01-02 09:27:00+05:30  18114.95   Hold             Sell\n",
      "8  2023-01-02 09:28:00+05:30  18116.65   Hold             Sell\n",
      "9  2023-01-02 09:29:00+05:30  18131.00   Hold             Sell\n",
      "10 2023-01-02 09:30:00+05:30  18131.00   Hold             Sell\n",
      "11 2023-01-02 09:31:00+05:30  18114.65   Hold             Sell\n",
      "12 2023-01-02 09:32:00+05:30  18109.15   Hold             Sell\n",
      "13 2023-01-02 09:33:00+05:30  18103.70   Hold             Sell\n",
      "14 2023-01-02 09:34:00+05:30  18101.85   Hold             Sell\n",
      "15 2023-01-02 09:35:00+05:30  18094.35   Hold             Hold\n",
      "16 2023-01-02 09:36:00+05:30  18103.20   Hold             Sell\n",
      "17 2023-01-02 09:37:00+05:30  18096.25   Hold             Sell\n",
      "18 2023-01-02 09:38:00+05:30  18112.45   Hold             Sell\n",
      "19 2023-01-02 09:39:00+05:30  18123.05   Hold             Hold\n"
     ]
    }
   ],
   "source": [
    "#from indicators.py file calcilating all indicators\n",
    "#from signal_engine.py file calculating composite signal based on indicators\n",
    "# Done : INdicator & Signal engine\n",
    "from indicators import compute_all\n",
    "from signal_engine import compute_composite\n",
    "import pandas as pd\n",
    "\n",
    "# Load spot\n",
    "spot = pd.read_csv(\"data/spot_with_signals_2023.csv\", parse_dates=[\"datetime\",\"closest_expiry\"])\n",
    "\n",
    "# Compute indicators\n",
    "spot = compute_all(spot)\n",
    "\n",
    "# Compute composite signal\n",
    "spot = compute_composite(spot)\n",
    "\n",
    "print(spot[['datetime','close','signal','composite_signal']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1e3462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>closest_expiry</th>\n",
       "      <th>ap</th>\n",
       "      <th>esa</th>\n",
       "      <th>d</th>\n",
       "      <th>ci</th>\n",
       "      <th>tci</th>\n",
       "      <th>wt1</th>\n",
       "      <th>wt2</th>\n",
       "      <th>rsi</th>\n",
       "      <th>cross</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02 03:50:00</td>\n",
       "      <td>18131.70</td>\n",
       "      <td>18150.15</td>\n",
       "      <td>18117.55</td>\n",
       "      <td>18141.35</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18125.43</td>\n",
       "      <td>18129.07</td>\n",
       "      <td>23.75</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-57.78</td>\n",
       "      <td>39.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02 03:51:00</td>\n",
       "      <td>18142.20</td>\n",
       "      <td>18145.70</td>\n",
       "      <td>18131.40</td>\n",
       "      <td>18135.65</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18125.43</td>\n",
       "      <td>18129.07</td>\n",
       "      <td>23.75</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-57.78</td>\n",
       "      <td>39.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02 03:52:00</td>\n",
       "      <td>18133.25</td>\n",
       "      <td>18140.55</td>\n",
       "      <td>18120.65</td>\n",
       "      <td>18140.55</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18125.43</td>\n",
       "      <td>18129.07</td>\n",
       "      <td>23.75</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-57.78</td>\n",
       "      <td>39.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-02 03:53:00</td>\n",
       "      <td>18139.40</td>\n",
       "      <td>18139.40</td>\n",
       "      <td>18120.15</td>\n",
       "      <td>18130.75</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18125.43</td>\n",
       "      <td>18129.07</td>\n",
       "      <td>23.75</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-57.78</td>\n",
       "      <td>39.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-02 03:54:00</td>\n",
       "      <td>18130.30</td>\n",
       "      <td>18133.55</td>\n",
       "      <td>18113.05</td>\n",
       "      <td>18113.10</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18125.43</td>\n",
       "      <td>18129.07</td>\n",
       "      <td>23.75</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-53.39</td>\n",
       "      <td>-57.78</td>\n",
       "      <td>39.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-02 03:55:00</td>\n",
       "      <td>18115.75</td>\n",
       "      <td>18125.90</td>\n",
       "      <td>18097.50</td>\n",
       "      <td>18117.85</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18122.57</td>\n",
       "      <td>18127.88</td>\n",
       "      <td>20.39</td>\n",
       "      <td>-17.36</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-55.32</td>\n",
       "      <td>44.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-02 03:56:00</td>\n",
       "      <td>18118.65</td>\n",
       "      <td>18126.50</td>\n",
       "      <td>18117.60</td>\n",
       "      <td>18122.75</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18122.57</td>\n",
       "      <td>18127.88</td>\n",
       "      <td>20.39</td>\n",
       "      <td>-17.36</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-55.32</td>\n",
       "      <td>44.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-02 03:57:00</td>\n",
       "      <td>18122.25</td>\n",
       "      <td>18122.25</td>\n",
       "      <td>18111.10</td>\n",
       "      <td>18114.95</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18122.57</td>\n",
       "      <td>18127.88</td>\n",
       "      <td>20.39</td>\n",
       "      <td>-17.36</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-55.32</td>\n",
       "      <td>44.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-02 03:58:00</td>\n",
       "      <td>18114.40</td>\n",
       "      <td>18116.65</td>\n",
       "      <td>18106.50</td>\n",
       "      <td>18116.65</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18122.57</td>\n",
       "      <td>18127.88</td>\n",
       "      <td>20.39</td>\n",
       "      <td>-17.36</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-55.32</td>\n",
       "      <td>44.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-02 03:59:00</td>\n",
       "      <td>18117.70</td>\n",
       "      <td>18139.20</td>\n",
       "      <td>18116.55</td>\n",
       "      <td>18131.00</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>18122.57</td>\n",
       "      <td>18127.88</td>\n",
       "      <td>20.39</td>\n",
       "      <td>-17.36</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-50.12</td>\n",
       "      <td>-55.32</td>\n",
       "      <td>44.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      open      high       low     close closest_expiry  \\\n",
       "0 2023-01-02 03:50:00  18131.70  18150.15  18117.55  18141.35     2023-01-05   \n",
       "1 2023-01-02 03:51:00  18142.20  18145.70  18131.40  18135.65     2023-01-05   \n",
       "2 2023-01-02 03:52:00  18133.25  18140.55  18120.65  18140.55     2023-01-05   \n",
       "3 2023-01-02 03:53:00  18139.40  18139.40  18120.15  18130.75     2023-01-05   \n",
       "4 2023-01-02 03:54:00  18130.30  18133.55  18113.05  18113.10     2023-01-05   \n",
       "5 2023-01-02 03:55:00  18115.75  18125.90  18097.50  18117.85     2023-01-05   \n",
       "6 2023-01-02 03:56:00  18118.65  18126.50  18117.60  18122.75     2023-01-05   \n",
       "7 2023-01-02 03:57:00  18122.25  18122.25  18111.10  18114.95     2023-01-05   \n",
       "8 2023-01-02 03:58:00  18114.40  18116.65  18106.50  18116.65     2023-01-05   \n",
       "9 2023-01-02 03:59:00  18117.70  18139.20  18116.55  18131.00     2023-01-05   \n",
       "\n",
       "         ap       esa      d     ci    tci    wt1    wt2    rsi  cross signal  \n",
       "0  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78  39.45    NaN   Hold  \n",
       "1  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78  39.45    NaN   Hold  \n",
       "2  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78  39.45    NaN   Hold  \n",
       "3  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78  39.45    NaN   Hold  \n",
       "4  18125.43  18129.07  23.75 -10.22 -53.39 -53.39 -57.78  39.45    NaN   Hold  \n",
       "5  18122.57  18127.88  20.39 -17.36 -50.12 -50.12 -55.32  44.29    NaN   Hold  \n",
       "6  18122.57  18127.88  20.39 -17.36 -50.12 -50.12 -55.32  44.29    NaN   Hold  \n",
       "7  18122.57  18127.88  20.39 -17.36 -50.12 -50.12 -55.32  44.29    NaN   Hold  \n",
       "8  18122.57  18127.88  20.39 -17.36 -50.12 -50.12 -55.32  44.29    NaN   Hold  \n",
       "9  18122.57  18127.88  20.39 -17.36 -50.12 -50.12 -55.32  44.29    NaN   Hold  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc77d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime signal composite_signal\n",
      "0 2023-01-02 03:50:00   Hold             Hold\n",
      "1 2023-01-02 03:51:00   Hold             Sell\n",
      "2 2023-01-02 03:52:00   Hold             Sell\n",
      "3 2023-01-02 03:53:00   Hold             Sell\n",
      "4 2023-01-02 03:54:00   Hold             Sell\n",
      "5 2023-01-02 03:55:00   Hold             Sell\n",
      "6 2023-01-02 03:56:00   Hold             Sell\n",
      "7 2023-01-02 03:57:00   Hold             Sell\n",
      "8 2023-01-02 03:58:00   Hold             Sell\n",
      "9 2023-01-02 03:59:00   Hold             Sell\n",
      "           entry_time           exit_time signal  spot_close     expiry  \\\n",
      "0 2023-01-02 09:15:00 2023-01-02 09:16:00    Buy    18154.10 2023-01-05   \n",
      "1 2023-01-02 09:16:00 2023-01-02 09:19:00    Buy    18157.45 2023-01-05   \n",
      "2 2023-01-02 09:17:00 2023-01-02 09:18:00    Buy    18162.45 2023-01-05   \n",
      "3 2023-01-02 09:18:00 2023-01-02 09:19:00    Buy    18160.70 2023-01-05   \n",
      "4 2023-01-02 09:19:00 2023-01-02 09:24:00    Buy    18156.70 2023-01-05   \n",
      "5 2023-01-02 09:20:00 2023-01-02 09:22:00    Buy    18158.35 2023-01-05   \n",
      "6 2023-01-02 09:23:00 2023-01-02 09:24:00    Buy    18184.40 2023-01-05   \n",
      "7 2023-01-02 09:31:00 2023-01-02 09:32:00    Buy    18198.45 2023-01-05   \n",
      "8 2023-01-02 09:33:00 2023-01-02 09:34:00    Buy    18191.90 2023-01-05   \n",
      "9 2023-01-02 09:43:00 2023-01-02 09:44:00   Sell    18181.30 2023-01-05   \n",
      "\n",
      "    strike option_type  entry_price  exit_price   pnl  \n",
      "0  18150.0          PE       107.55      110.85 -3.30  \n",
      "1  18150.0          PE       110.85      117.35 -6.50  \n",
      "2  18150.0          PE       108.00      109.75 -1.75  \n",
      "3  18150.0          PE       109.75      117.35 -7.60  \n",
      "4  18150.0          PE       117.35      110.10  7.25  \n",
      "5  18150.0          PE       115.45      117.70 -2.25  \n",
      "6  18200.0          PE       145.15      137.85  7.30  \n",
      "7  18200.0          PE       153.50      155.95 -2.45  \n",
      "8  18200.0          PE       147.25      140.90  6.35  \n",
      "9  18200.0          CE        78.75       85.50 -6.75  \n",
      "(17, 10)\n"
     ]
    }
   ],
   "source": [
    "#baktesting for 1 day  based on prepare_trades_for_day after indicator & signal engine\n",
    "from indicators import compute_all\n",
    "from signal_engine import compute_composite\n",
    "\n",
    "# Load raw spot data\n",
    "spot = load_spot_data()\n",
    "\n",
    "# Step 1: Add indicators\n",
    "spot = compute_all(spot)\n",
    "\n",
    "# Step 2: Add composite signal\n",
    "spot = compute_composite(spot)\n",
    "\n",
    "# Now spot has 'composite_signal'\n",
    "print(spot[['datetime','signal','composite_signal']].head(10))\n",
    "\n",
    "# Load options data\n",
    "options = load_options_data()\n",
    "\n",
    "# Step 3: Prepare trades\n",
    "df_trades = prepare_trades_for_day(spot, options, \"2023-01-02\")\n",
    "print(df_trades.head(10))\n",
    "print(df_trades.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0769eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
